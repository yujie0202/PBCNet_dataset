{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa605985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "code_path = os.path.dirname(os.path.abspath(\".\")).rsplit(\"/\",1)[0]\n",
    "import sys\n",
    "sys.path.append(code_path + '/model_code')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import sys\n",
    "import random\n",
    "from Dataloader.dataloader import collate_fn, LeadOptDataset\n",
    "from utilis.function import get_loss_func\n",
    "from utilis.trick import Writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e015d542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yujie/code230118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b94a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def freezen(model):\n",
    "    need_updata = ['FNN.0.weight', 'FNN.0.bias', 'FNN.2.weight', 'FNN.2.bias', 'FNN.4.weight', 'FNN.4.bias', 'FNN.6.weight', 'FNN.6.bias',\n",
    "                   'FNN2.0.weight', 'FNN2.0.bias', 'FNN2.2.weight', 'FNN2.2.bias', 'FNN2.4.weight', 'FNN2.4.bias', 'FNN2.6.weight', 'FNN2.6.bias']\n",
    "\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if name in need_updata:\n",
    "            parameter.requires_grad = False\n",
    "        else:\n",
    "            parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3d0112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_generation(file_name, ref, newly_mols):\n",
    "    \n",
    "    # /home/yujie/code230118/data/selection_graph/\n",
    "\n",
    "    if os.path.exists(f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/\") is False:\n",
    "        os.system(f' mkdir \"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/\" ')\n",
    "\n",
    "    ligand1_tra = []\n",
    "    ligand2_tra = []\n",
    "    Lable1_tra = []\n",
    "    Lable2_tra = []\n",
    "    Lable_tra = []\n",
    "    Rank1_tra = []\n",
    "    Rank2_tra = []\n",
    "    Rank_last_tra = []\n",
    "    ligand1_num_tra = []\n",
    "    ligand2_num_tra = []\n",
    "    reference_num_tra = []\n",
    "\n",
    "    ligand1_val = []\n",
    "    ligand2_val = []\n",
    "    Lable1_val = []\n",
    "    Lable2_val = []\n",
    "    Lable_val = []\n",
    "    Rank1_val = []\n",
    "    Rank2_val = []\n",
    "    Rank_last_val = []\n",
    "    ligand1_num_val = []\n",
    "    ligand2_num_val = []\n",
    "    reference_num_val = []\n",
    "\n",
    "\n",
    "    # 加载该系列化合物中所有的化合物\n",
    "    file_name_ = f\"{code_path}/data/selection_graph/{file_name}/\"\n",
    "\n",
    "    ligands = [i for i in os.listdir(file_name_) if\n",
    "               i.rsplit(\".\", 1)[-1] == \"pkl\" and i.rsplit(\".\", 1)[0] != \"pocket\"]\n",
    "\n",
    "    ligands = [f\"{code_path}/data/selection_graph/{file_name}/\" + i for i in ligands]\n",
    "\n",
    "    # 加载上一轮迭代之前所有的refs\n",
    "    pd_for_refs = pd.read_csv(f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref-3}_reference/predict.csv\")\n",
    "    refs = list(set(pd_for_refs.Ligand2_num.values))\n",
    "    # 和最新的3个ref合并\n",
    "    refs.extend(newly_mols)\n",
    "    refs = [f\"{code_path}/data/selection_graph/{file_name}/{file_name}_\" + i + \".pkl\" for i in refs]\n",
    "\n",
    "    # label\n",
    "    label_csv = f\"{code_path}/data/selection/{file_name}_pose/label.csv\"\n",
    "    df = pd.read_csv(label_csv)\n",
    "\n",
    "\n",
    "    for i in range(len(refs)):\n",
    "\n",
    "        reference_ligand = refs[i]\n",
    "\n",
    "        reference_ligand_number = i + 1\n",
    "\n",
    "        # finetune\n",
    "        for query_ligand in refs:\n",
    "\n",
    "            if query_ligand == reference_ligand:\n",
    "                continue\n",
    "\n",
    "            ligand1_val.append(query_ligand)\n",
    "            ligand2_val.append(reference_ligand)\n",
    "\n",
    "            ligand1_number = str(query_ligand.rsplit('.', 1)[0].split(\"/\")[-1].split(\"_\", 1)[1])\n",
    "            ligand2_number = str(reference_ligand.rsplit('.', 1)[0].split(\"/\")[-1].split(\"_\", 1)[1])\n",
    "\n",
    "            ligand1_num_val.append(ligand1_number)\n",
    "            ligand2_num_val.append(ligand2_number)\n",
    "\n",
    "            lable1 = float(df[df.name == ligand1_number].pIC50)\n",
    "            lable2 = float(df[df.name == ligand2_number].pIC50)\n",
    "            Lable1_val.append(lable1)\n",
    "            Lable2_val.append(lable2)\n",
    "            Lable_val.append(lable1 - lable2)\n",
    "\n",
    "            index1 = ligands.index(query_ligand)\n",
    "            index2 = ligands.index(reference_ligand)\n",
    "            Rank1_val.append(index1)\n",
    "            Rank2_val.append(index2)\n",
    "            Rank_last_val.append(max(index1, index2))\n",
    "            reference_num_val.append(reference_ligand_number)\n",
    "\n",
    "        # predict\n",
    "        for query_ligand in ligands:\n",
    "            if query_ligand in refs:\n",
    "                continue\n",
    "\n",
    "            ligand1_tra.append(query_ligand)\n",
    "            ligand2_tra.append(reference_ligand)\n",
    "\n",
    "            ligand1_number = str(query_ligand.rsplit('.', 1)[0].split(\"/\")[-1].split(\"_\", 1)[1])\n",
    "            ligand2_number = str(reference_ligand.rsplit('.', 1)[0].split(\"/\")[-1].split(\"_\", 1)[1])\n",
    "\n",
    "            ligand1_num_tra.append(ligand1_number)\n",
    "            ligand2_num_tra.append(ligand2_number)\n",
    "\n",
    "            lable1 = float(df[df.name == ligand1_number].pIC50)\n",
    "            lable2 = float(df[df.name == ligand2_number].pIC50)\n",
    "\n",
    "            Lable1_tra.append(lable1)\n",
    "            Lable2_tra.append(lable2)\n",
    "            Lable_tra.append(lable1 - lable2)\n",
    "\n",
    "            index1 = ligands.index(query_ligand)\n",
    "            index2 = ligands.index(reference_ligand)\n",
    "            Rank1_tra.append(index1)\n",
    "            Rank2_tra.append(index2)\n",
    "            Rank_last_tra.append(max(index1, index2))\n",
    "            reference_num_tra.append(reference_ligand_number)\n",
    "\n",
    "    df_predict = pd.DataFrame(\n",
    "        {'reference_num': reference_num_tra,\n",
    "         'Ligand1': ligand1_tra, \"Ligand2\": ligand2_tra, \"Lable\": Lable_tra, \\\n",
    "         \"Lable1\": Lable1_tra, \"Lable2\": Lable2_tra, \\\n",
    "         \"Rank1\": Rank1_tra, \"Rank2\": Rank2_tra, \"Rank\": Rank_last_tra, \"Ligand1_num\": ligand1_num_tra, \\\n",
    "         \"Ligand2_num\": ligand2_num_tra})\n",
    "\n",
    "    df_finetune = pd.DataFrame(\n",
    "        {'reference_num': reference_num_val,\n",
    "         'Ligand1': ligand1_val, \"Ligand2\": ligand2_val, \"Lable\": Lable_val, \\\n",
    "         \"Lable1\": Lable1_val, \"Lable2\": Lable2_val, \\\n",
    "         \"Rank1\": Rank1_val, \"Rank2\": Rank2_val, \"Rank\": Rank_last_val, \"Ligand1_num\": ligand1_num_val, \\\n",
    "         \"Ligand2_num\": ligand2_num_val})\n",
    "\n",
    "    new_ref_pre_csv =  f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/predict.csv\"\n",
    "    new_ref_fin_csv = f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/finetune.csv\"\n",
    "\n",
    "    df_predict.to_csv(new_ref_pre_csv, index=0)\n",
    "    df_finetune.to_csv(new_ref_fin_csv, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce116085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(file_name, ref, model, device, logger_writer,beita=-2):\n",
    "    # 加载需要predict的数据\n",
    "    test_dataset = LeadOptDataset(\n",
    "        f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/predict.csv\")\n",
    "    test_dataloader = GraphDataLoader(test_dataset, collate_fn=collate_fn, batch_size=20,\n",
    "                                      drop_last=False, shuffle=False)\n",
    "    # 通过原始的文献获得predict的mol的信息\n",
    "    t_pd = pd.read_csv(f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/predict.csv\")\n",
    "    names = t_pd.Ligand1_num.values\n",
    "\n",
    "    # 预测\n",
    "    pres = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    for batch_data in test_dataloader:\n",
    "        graph1, graph2, pock, label, label1, label2, rank1, file_name = batch_data\n",
    "        # to cuda\n",
    "        graph1, graph2, pock, label, label1, label2 = graph1.to(device), graph2.to(device), pock.to(\n",
    "            device), label.to(device), label1.to(\n",
    "            device), label2.to(device)\n",
    "        logits, _, _, _ = model(graph1,\n",
    "                                graph2,\n",
    "                                pock)\n",
    "        pre = logits.squeeze() + label2\n",
    "        labels += label1.tolist()\n",
    "        pres += pre.tolist()\n",
    "\n",
    "    result_df = pd.DataFrame({\"pre\": pres, \"label\": labels, \"mol_name\": names})\n",
    "\n",
    "    if ref != 1:\n",
    "        std_ = result_df.groupby('mol_name')[['pre', 'label']].std().reset_index().pre.values\n",
    "\n",
    "    result_df = result_df.groupby('mol_name')[['pre', 'label']].mean().reset_index()\n",
    "    if ref != 1:\n",
    "        result_df[\"uncertainty\"] = std_\n",
    "\n",
    "    s = result_df[[\"pre\", \"label\"]].corr(method='spearman').iloc[0, 1]\n",
    "    p = result_df[[\"pre\", \"label\"]].corr(method='pearson').iloc[0, 1]\n",
    "\n",
    "    mol_name = result_df.mol_name.values\n",
    "    pre_ic50 = result_df.pre.values\n",
    "    if ref != 1:\n",
    "        uncertainty = result_df.uncertainty.values\n",
    "    if ref != 1:\n",
    "        ucb = pre_ic50 + beita * uncertainty\n",
    "    else:\n",
    "        ucb = pre_ic50\n",
    "\n",
    "    ind = np.argsort(ucb)[-3:][::-1]\n",
    "    # ind = np.argsort(pre_ic50)[-3:][::-1]\n",
    "    ind = mol_name[ind]\n",
    "\n",
    "    logger_writer(f\"Prediction:\")\n",
    "    logger_writer(f\"    reference number: {ref}\")\n",
    "    logger_writer(f\"    spearman: {s}\")\n",
    "    logger_writer(f\"    pearson: {p}\")\n",
    "    logger_writer(f\"    selected molecule: {ind}\")\n",
    "    logger_writer(f\" \")\n",
    "\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b1ca9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_finetune(file_name, ref, model, device, logger_writer,lr=0.000001):\n",
    "    train_dataset = LeadOptDataset(\n",
    "        f\"{code_path}/data/selection_graph/{file_name}/input_file/{ref}_reference/finetune.csv\")\n",
    "    train_dataloader = GraphDataLoader(train_dataset, collate_fn=collate_fn, batch_size=20,\n",
    "                                       drop_last=False, shuffle=False)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_func = get_loss_func(\"mse\")\n",
    "    for epoch in range(3):\n",
    "        model.train()\n",
    "        for batch_data in train_dataloader:\n",
    "            graph1, graph2, pock, label, label1, label2, rank1, file_name = batch_data\n",
    "            # to cuda\n",
    "            graph1, graph2, pock, label, label1, label2 = graph1.to(device), graph2.to(device), pock.to(\n",
    "                device), label.to(device), label1.to(\n",
    "                device), label2.to(device)\n",
    "\n",
    "            logits, logits_class, _, _ = model(graph1,\n",
    "                                               graph2, pock)\n",
    "            loss = loss_func(logits.squeeze(dim=-1).float(), label.float())\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    logger_writer(f\"Finetuned with {ref} molecules.\")\n",
    "    # print(f\"Finetuned with {ref} molecules.\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8dd4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mols = \\\n",
    "    {'FGFR2': ['lig_38'],\n",
    "     'BCL6':  ['lig_1'],\n",
    "     'HO1':   ['lig_7i'],\n",
    "     'LRRK2': ['lig_11'],\n",
    "     'sEH':   ['lig_11h'],\n",
    "     'CDK9':  ['lig_16'],\n",
    "     'WDR5':  ['lig_27'],\n",
    "     'AAK1':  ['lig_(S)-32'],\n",
    "     'PSK13': ['lig_37']}\n",
    "\n",
    "device = \"cuda:1\"\n",
    "seed = [1,2,3,4,5,6]\n",
    "\n",
    "select_files = [\"sEH\", 'FGFR2', 'HO1', 'LRRK2', 'CDK9',  'WDR5', 'AAK1', 'BCL6', 'PSK13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beita = [2,-2,0]\n",
    "\n",
    "for beita in Beita:\n",
    "    print(beita)\n",
    "    for sd in seed:\n",
    "        setup_seed(sd)\n",
    "        print(f\"seed:{sd}\")\n",
    "        for file_name in select_files:\n",
    "            print(file_name)\n",
    "            if file_name == 'CDK9':\n",
    "                lr = 0.01\n",
    "            # 记录\n",
    "            logger_writer = Writer(f\"{code_path}/record_activelearning.txt\")\n",
    "            logger_writer(file_name)\n",
    "\n",
    "            model = torch.load(\n",
    "                f\"{code_path}/PBCNet.pth\",\n",
    "                map_location=\"cpu\")\n",
    "            model.to(device)\n",
    "            # freezen(model)\n",
    "\n",
    "            order = []\n",
    "            for ref in range(1, 1000, 3):\n",
    "\n",
    "\n",
    "                # 第一轮不需要finetune\n",
    "                if ref == 1:\n",
    "                    selected_mols = model_predict(file_name, ref, model, device, logger_writer,beita)\n",
    "                else:\n",
    "                    input_generation(file_name, ref, newly_mols=selected_mols)\n",
    "\n",
    "                    # model = model_finetune(file_name, ref, model, device, logger_writer)\n",
    "                    # selected_mols = model_predict(file_name, ref, model, device, logger_writer)\n",
    "\n",
    "                    # connected\n",
    "                    model2 = model_finetune(file_name, ref, model, device, logger_writer,lr)\n",
    "                    selected_mols = model_predict(file_name, ref, model2, device, logger_writer,beita)\n",
    "\n",
    "                # 判断新挑选的化合物小分子是否为最佳的(之一)\n",
    "                n = 0\n",
    "                for selected_mol in selected_mols:\n",
    "                    n += 1\n",
    "                    if selected_mol in best_mols[file_name]:\n",
    "                        best_mols[file_name].remove(selected_mol)\n",
    "\n",
    "                        order.append(ref - 1 + n)\n",
    "\n",
    "                        logger_writer(f\"{selected_mol} is selected!\")\n",
    "                        logger_writer(f\"order: {ref - 1 + n}\")\n",
    "                        logger_writer(\" \")\n",
    "\n",
    "                # 判断是否需要继续迭代\n",
    "                if not best_mols[file_name]:\n",
    "                    logger_writer(f\"The iteration of AL is over!\")\n",
    "                    break\n",
    "\n",
    "            logger_writer(f\"{file_name} each order is {order}, mean order is {np.mean(order)}\")\n",
    "            print(f\"{file_name} each order is {order}, mean order is {np.mean(order)}\")\n",
    "            logger_writer(\" \")\n",
    "            logger_writer(\" \")\n",
    "            logger_writer(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974aecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
